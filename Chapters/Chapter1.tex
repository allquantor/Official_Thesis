
\chapter{Introduction}
\epigraph{All positive examples are
alike, each negative example
is negative in its own way.}{Found on the Internet}
\label{intro}

Anomaly is rare and it represents an outlier, i.e., atypical case. The Concise Oxford Dictionary of Mathematics~\cite{Clapham:2013} defines an anomaly as an unusual and possibly erroneous observation that does not follow the general pattern of a drawn population. Anomaly detection is a branch of data mining that seeks to find data points or patterns that do not fit to the overall pattern of the data. Studying anomalous behavior has been done in many applied areas such as network security \cite{Peddabachigari:2007}, financial transactions \cite{Eskin:2010,Ahmed:2015}, medical imaging~\cite{Spence:2001:DSC:882464.882797}, industrial damage detection \cite{Hollier:Austin:2002} and in earth science \cite{Das:2009:ADS:1601966.1601989}, to name a few. As rare observations often carry important information, their proper detection is of great importance in practice. 

This thesis concentrates on anomaly detection in consumer micro-credit lending by using the state-of-the-art data mining methods. 

A micro-credit is usually a small to medium sized loan issued to a private person for a relatively short period of time. A borrower that needs a loan submits an application via a web interface that gathers borrower's personal and financial information, such as name, address of residence, monthly or yearly income, other loans, etc. An data mining algorithm behind the automatic loan application scoring utilizes this information as well as any extra available information, e.g., such as data on creditworthiness of an applicant from credit bureaus, technical characteristics of a device used to submit an application and information describing the behaviour on the web-site, in order to make a decision of whether to issue a loan or to reject the application. 

It is not uncommon that malicious people known as fraudsters attempt to cheat a scoring algorithm so as to look as legitimate and trustworthy applicants. Once such a fraudster got a loan, a  micro-crediting company loses money. As the by-product of missed fraud attempt, a bad debt is accumulated too, which handicaps the ability of such a company to issue loans to legitimate applicants in the future. Because a loan decision is automatic and it has to be fast (made in a few dozen minutes), reliable fraud detection is of paramount importance for lending businesses. 

The fraud is not the only anomaly in this area. For instance, a borrower that repeatedly gets and fully repays large loans is rarity, but it is a positive rarity that clearly stands out of the entire cohort of applicants. Such applicants likely demand special attention in order to keep them satisfied with the service and loan conditions.

In this chapter, the taxonomy of anomalies will first be introduced, followed by a list of challenges and problems encountered in anomaly detection. After that, typical approaches to anomaly detection are briefly sketched together with examples from the literature. Finally, the goal and the structure of the thesis are outlined.

\section{Types of Anomalies}\label{taxonomyofanomalies}
According to~\cite{Chandola:2009:ADS:1541880.1541882}, anomalies can be divided into three categories:
\begin{itemize}
    \item \textit{Point} is the simplest type of an anomaly. Given that an observation is described by several features (attributes, characteristics), the point anomaly only affects one of them, thus treating any feature independently of the others. For instance, a loan decision is made based on applicant's salary only. A salary is therefore a feature to consider. A salary that is extremely high with respect to the rest of salaries is thus the point anomaly.

    \item \textit{Context} is an extension of the point anomaly when several features are taken into account at once, thus assuming certain dependence among features. By extending the example above, not only salary but also a country of residence are taken into account. In this case, a salary is linked to the country where a loan applicant lives: a salary of 1,000 euro can be seen as too high in one country, while in another country the same amount corresponds to a typical (average) salary.

    \item \textit{Collective} anomalies can be detected by observing a collection of observations. The context anomaly still views each observation somewhat in isolation from other observations. The collective anomaly manifests itself only when a few observations are jointly analyzed. Each observation by itself does not look anomalous, but a group of such observations occurred together constitutes the anomaly. It is often that such a group is formed when considering the time dimension. For example, somebody did not yet repaid one loan but already got the next one, even though the rules explicitly prohibit this. In isolation, getting a loan is a normal event, but getting two loans when the first loan is not yet fully repaid is likely to be abnormal.
\end{itemize}

The collective anomaly is out of the scope in this work as it requires approaches drastically different from those used to address the first two types of anomalies.

\section{Challenges and Problems}\label{challenges}
Given a statistical/machine learning/data mining algorithm, determining whether an observation is an anomaly or not is closely tied to the questions: What is a normal state and how this state can be characterized so that an algorithm can distinguish the normal and abnormal state? 

The following challenges are common:
\begin{itemize}
    \item Rarity of labeled anomalous observations~\cite{Weiss:2004:MRU:1007730.1007734}. Human observers can manually label few of anomalies, but this is tedious and requires domain knowledge experts. In addition, anomalous patterns may not yet occurred, so that there are representatives of one (normal) class only.
    
    \item Distinguishing between noise in normal data and genuine anomalies is hard and misclassification leads to a high false positive (false alarm)  or false negative  (no alarm) rate~\cite{Chandola:2009:ADS:1541880.1541882}.   % noise in glossary, false positive in glossary

    \item Due to the rarity of anomalous observations, it is hard to establish the \textit{ground-truth} to objectively judge on algorithm performance~\cite{Aggarwal:2013}. %seite 33
    
    \item Anomalous pattern is not static and can evolve over time. A pattern that is anomalous at a given point in time may not be anomalous in the future~\cite{Chandola:2009:ADS:1541880.1541882}.
\end{itemize}

\section{Statistical and Machine Learning Approaches to Anomaly Detection}\label{approaches2problem}
According to~\cite{Aggarwal:2013}, there are the following approaches to anomaly detection that rely on either statistical or machine learning algorithms.

\subsection{Extreme-value analysis}\label{extremevalue}
This approach is based on the extreme value theory \cite{Castillo:2004}. It is a distribution based and is typically applied to 1-dimensional data by looking at the tails of a data distribution. This limits its usefulness to the point anomaly detection.

\subsection{Proximity-based approach}\label{proximity}
The major idea of the proximity-based approach is to pool related data sets to groups or cluster based on available data. Data points that are not been allocated to any groups are likely the outliers. There are two main subgroups in this approach: density-based and clustering approaches. Regardless of this division, the main operation is distance computation between pairs of observations. For high-dimensional data, however, distances tend to become almost identical, thus making outlier detection hard. 

\subsection{Classification approach}\label{classification}
Anomaly detection can be modeled as a two- or one-class classification (supervised learning) problem. 

In the former case, two classes of data are assumed to be available: normal and abnormal. To mitigate class imbalance caused by very few representatives of anomaly, the cost-sensitive learning is applied that assigns different misclassification costs to different classes (cost of misclassifying an anomalous observation is set to be much higher than that of misclassifying a normal observation) \cite{Elkan:2001:FCL:1642194.1642224}.

In one-class classification, only representatives of the normal class are given and an algorithm is trained to detect them. What cannot be assigned to the normal class is considered to be an anomaly \cite{Amer:2013:EOS:2500853.2500857}.

Although the two-class approach might look more attractive since the conventional supervised learning algorithms modified to deal with misclassification costs can readily be applied, setting these costs is not a trivial task often demanding expert's knowledge. The one-class approach that does not need the prior cost specification is therefore more appealing and will be pursued in this thesis. 

It should be noted that with either approach there is a risk of the inflated false positive rate, compared to the cases with well-balanced classes. However, this is a challenge and an unavoidable price to pay when anomalous observations are scarce or unavailable.

In recent years, scholars came to the idea of utilizing unlabeled data to complement labeled data and use both types of data for training a predictive algorithm. This type of learning is termed semi-supervised learning \cite{Zhu:2008}. One example of this approach is positive and unlabeled learning (PUL) \cite{Elkan;Noto:2008} that is particularly suitable for our task as will be explained below.

As anomaly is caused by different reasons and accurate anomaly detection is often hard to achieve, it is advisable to apply an ensemble of classifiers where predictions of individual classifiers - ensemble members - are combined into a single prediction \cite{Seni:2010:EMD:1841412}. 
Ensemble learning is a machine learning paradigm where multiple learners are trained to solve the same problem. In contrast
to ordinary machine learning approaches which try to learn one hypothesis from training data, ensemble methods try to
construct a set of hypotheses and combine them to use \cite{Zhou:2012}.

% Ensemble members do not need to be sophisticated algorithms trying to address each and every aspect of anomaly detection; instead each algorithm in an ensemble is sufficient to concentrate on a rather narrow task, making it well focused. The combination of independent classifiers whose predictions complement rather than duplicate each other is the reason behind the success of ensembles and their superiority over single sophisticated algorithms. 



\section{Current State in Research}\label{state-of-the-art}
Numerous scientific surveys~\cite{Agyemang:2006:CSN:1609942.1609946,Chandola:2009:ADS:1541880.1541882,Chandola:2012:ADD:2197072.2197116,Pimentel:2014:RRN:2588908.2589196} discuss anomaly detection for particular domains from different points of view. To provide more specific review, this survey consider only domains that are also treating with malicious behavior. Anomaly detection in use case of \textit{Credit Card Fraud} is well researched for different techniques like Clustering, Nearest Neighbor, SVM, \cite{Eskin:2010}, Neural Networks \cite{Ghosh;Reilly;1994} or Statistical modeling \cite{Agarwal:2005} to name a few. The domain of \textit{Intrusion Detection} treat anomalies indicative for malicious actions in networks, some techniques which are used for this problem are Positive Unlabeled Learning (PUL) \cite{Eskin:2010}, one class SVM \cite{Amer:2013:EOS:2500853.2500857}, Clustering \cite{Chandola:2006} or Rule based systems \cite{Salvador:2005}. However, no one of the reviewed works treat anomaly detection in case of \textit{Credit Application Fraud} but the insights can be combined and used to develop an own outlier detection model. 
This work will stick on classification \ref{classification} approach by using Two Class SVM by \cite{Cortes;Vapnik:1995} and One Class SVM \cite{Tax:2004:SVD:960091.960109} as classification algorithms and PUL \cite{Elkan;Noto:2008} as the methodology for learning on SVM. %Ensembles & \cite{Nikunj:2009,Caruana:2004:ESL:1015330.1015432}


\section{Thesis Goal and Structure}\label{goalandstructure}
The goal in this work is to evaluate several machine learning algorithms for anomaly detection in the real world business use case. \\% The complete goal will be defined as last.
This thesis is structured as follows: Chapter \ref{ch:2} treat the data discovery and preprocessing instructed by the CRISP-DM process. The theoretical overview and discussion of Machine-learning algorithms used in this thesis is provided in chapter \ref{ch:3}. The following chapter \ref{Chapter:4} explain a technique to measure the results of applying Machine-learning methods on data. Chapter \ref{Chapter:5} describe the practical work done with given data. The results of experiments made are discussed in the \ref{Chapter:6}-th chapter. As last chapter \ref{Chapter:7} contain a summary about the work that has been done and will end with an overview of perspectives for the future research in anomaly detection topic. 
